{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiSpecific.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_gtFoV8BuRx"
      },
      "source": [
        "This is an example of SimSwap on processing video with multiple faces with designated sources.\n",
        "\n",
        "Code path: https://github.com/neuralchen/SimSwap\n",
        "Paper path: https://arxiv.org/pdf/2106.06340v1.pdf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y1RfpzsCAl9",
        "outputId": "75683c1e-5ce8-4269-830d-96ddb3d55879"
      },
      "source": [
        "## make sure you are using a runtime with GPU\n",
        "## you can check at Runtime/Change runtime type in the top bar.\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 19 12:47:55 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qzzx2UpDkqw"
      },
      "source": [
        "All file changes make by this notebook are temporary.\n",
        "You can try to mount your own google drive to store files if you wang.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_4CeWZCHLP",
        "outputId": "b5003b2e-0469-4863-965e-35838ee8acc8"
      },
      "source": [
        "!git clone https://github.com/neuralchen/SimSwap\n",
        "!cd SimSwap && git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SimSwap'...\n",
            "remote: Enumerating objects: 1141, done.\u001b[K\n",
            "remote: Counting objects: 100% (501/501), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 1141 (delta 416), reused 383 (delta 383), pack-reused 640 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1141/1141), 211.46 MiB | 41.62 MiB/s, done.\n",
            "Resolving deltas: 100% (602/602), done.\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5K4au_UCkKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b650b2-d3fa-4e95-b66c-1c5ff15a46c4"
      },
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface==0.2.1\n",
            "  Downloading insightface-0.2.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.26.4)\n",
            "Collecting onnx (from insightface==0.2.1)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.6.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (0.25.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.13)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.12.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.36.1)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (2024.12.14)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (2.8.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.2.1) (3.4.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.2.1) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.2.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface==0.2.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface==0.2.1) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface==0.2.1) (1.17.0)\n",
            "Downloading insightface-0.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.2.1 onnx-1.17.0 onnxruntime-1.20.1\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.11/dist-packages (0.4)\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio==2.4.1) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imageio==2.4.1) (11.1.0)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303884 sha256=c7ae109298507ab4a2ec879071fd5606a59ccdb1eeaaf92006f4909c92568c8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/28/50/248b15750b57c6b163d89d265f242e9cf6bce0bedfea3120aa\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.36.1\n",
            "    Uninstalling imageio-2.36.1:\n",
            "      Successfully uninstalled imageio-2.36.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\n",
            "scikit-image 0.25.0 requires imageio!=2.35.0,>=2.33, but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ7ZoIbLFCye",
        "outputId": "a8586f3c-7b80-4010-cc4e-9d51c930f0a1"
      },
      "source": [
        "import os\n",
        "os.chdir(\"SimSwap\")\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cog.yaml\t       options\t\t\t test_video_swap_multispecific.py\n",
            " crop_224\t       output\t\t\t test_video_swapsingle.py\n",
            " data\t\t       parsing_model\t\t test_video_swapspecific.py\n",
            " demo_file\t       pg_modules\t\t test_wholeimage_swapmulti.py\n",
            " docs\t\t       predict.py\t\t test_wholeimage_swap_multispecific.py\n",
            " download-weights.sh   README.md\t\t test_wholeimage_swapsingle.py\n",
            " insightface_func     'SimSwap colab.ipynb'\t test_wholeimage_swapspecific.py\n",
            " LICENSE\t       simswaplogo\t\t train.ipynb\n",
            " models\t\t       test_one_image.py\t train.py\n",
            " MultiSpecific.ipynb   test_video_swapmulti.py\t util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvGp-p0nOmKE"
      },
      "source": [
        "## You can upload filed manually\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLti1J0pEFjJ",
        "outputId": "e1ebde30-27ce-4be3-aaca-a35f8415863c"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "### it seems that google drive link may not be permenant, you can find this ID from our open url.\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1TLNdIufzwesDbyr_nVTR7Zrx9oRHLM_N',\n",
        "#                                     dest_path='./arcface_model/arcface_checkpoint.tar')\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1PXkRiBUYbu1xWpQyDEJvGKeqqUFthJcI',\n",
        "#                                     dest_path='./checkpoints.zip')\n",
        "\n",
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints\n",
        "!wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-19 12:48:44--  https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250119T124844Z&X-Amz-Expires=300&X-Amz-Signature=aef7f7721ac2f198496f76324a8b47681722e222c8af17866736237700be4ea5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-01-19 12:48:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250119T124844Z&X-Amz-Expires=300&X-Amz-Signature=aef7f7721ac2f198496f76324a8b47681722e222c8af17866736237700be4ea5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209280521 (200M) [application/octet-stream]\n",
            "Saving to: ‘./arcface_model/arcface_checkpoint.tar’\n",
            "\n",
            "arcface_checkpoint. 100%[===================>] 199.58M   116MB/s    in 1.7s    \n",
            "\n",
            "2025-01-19 12:48:46 (116 MB/s) - ‘./arcface_model/arcface_checkpoint.tar’ saved [209280521/209280521]\n",
            "\n",
            "--2025-01-19 12:48:47--  https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250119T124847Z&X-Amz-Expires=300&X-Amz-Signature=087957be8645de8bbdbff0b176fdced4ddff780efbb4a06aa20237245015ea14&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-01-19 12:48:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250119T124847Z&X-Amz-Expires=300&X-Amz-Signature=087957be8645de8bbdbff0b176fdced4ddff780efbb4a06aa20237245015ea14&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256461775 (245M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 244.58M   112MB/s    in 2.2s    \n",
            "\n",
            "2025-01-19 12:48:49 (112 MB/s) - ‘checkpoints.zip’ saved [256461775/256461775]\n",
            "\n",
            "Archive:  ./checkpoints.zip\n",
            "   creating: ./checkpoints/people/\n",
            "  inflating: ./checkpoints/people/iter.txt  \n",
            "  inflating: ./checkpoints/people/latest_net_D1.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_D2.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_G.pth  \n",
            "  inflating: ./checkpoints/people/loss_log.txt  \n",
            "  inflating: ./checkpoints/people/opt.txt  \n",
            "   creating: ./checkpoints/people/web/\n",
            "   creating: ./checkpoints/people/web/images/\n",
            "--2025-01-19 12:48:52--  https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250119T124853Z&X-Amz-Expires=300&X-Amz-Signature=0d78214d47112fcb7b9afda4d750ebaad071cb1ca82c8858238588048d5a64a6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-01-19 12:48:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250119%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250119T124853Z&X-Amz-Expires=300&X-Amz-Signature=0d78214d47112fcb7b9afda4d750ebaad071cb1ca82c8858238588048d5a64a6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘./parsing_model/checkpoint/79999_iter.pth’\n",
            "\n",
            "79999_iter.pth      100%[===================>]  50.82M   114MB/s    in 0.4s    \n",
            "\n",
            "2025-01-19 12:48:54 (114 MB/s) - ‘./parsing_model/checkpoint/79999_iter.pth’ saved [53289463/53289463]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ9DYRrCPIUL",
        "outputId": "ac4b39aa-4e4e-4a45-aab6-912415f51b31"
      },
      "source": [
        "!wget --no-check-certificate \"https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\" -O antelope.zip\n",
        "!unzip ./antelope.zip -d ./insightface_func/models/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-19 12:49:06--  https://sh23tw.dm.files.1drv.com/y4mmGiIkNVigkSwOKDcV3nwMJulRGhbtHdkheehR5TArc52UjudUYNXAEvKCii2O5LAmzGCGK6IfleocxuDeoKxDZkNzDRSt4ZUlEt8GlSOpCXAFEkBwaZimtWGDRbpIGpb_pz9Nq5jATBQpezBS6G_UtspWTkgrXHHxhviV2nWy8APPx134zOZrUIbkSF6xnsqzs3uZ_SEX_m9Rey0ykpx9w\n",
            "Resolving sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)... 13.107.42.12\n",
            "Connecting to sh23tw.dm.files.1drv.com (sh23tw.dm.files.1drv.com)|13.107.42.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-01-19 12:49:06 ERROR 404: Not Found.\n",
            "\n",
            "Archive:  ./antelope.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of ./antelope.zip or\n",
            "        ./antelope.zip.zip, and cannot find ./antelope.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfSsND36EMvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40756360-2949-4c0f-cb7e-f2a4dd7c169b"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import fractions\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from models.models import create_model\n",
        "from options.test_options import TestOptions\n",
        "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
        "from util.videoswap_multispecific import video_swap\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxSbZ2EDNDlf"
      },
      "source": [
        "def lcm(a, b): return abs(a * b) / fractions.gcd(a, b) if a and b else 0\n",
        "\n",
        "transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transformer_Arcface = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye8iS0UVPMRg",
        "outputId": "29ea5a9d-416d-4dc3-cda0-77ed89c1f4ec"
      },
      "source": [
        "!ls ./checkpoints"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "people\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwJOwR9LNKRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5989c0b-ba85-4ac6-fd59-d12ea9ed3e65"
      },
      "source": [
        "opt = TestOptions()\n",
        "opt.initialize()\n",
        "opt.parser.add_argument('-f') ## dummy arg to avoid bug\n",
        "opt = opt.parse()\n",
        "opt.multisepcific_dir = './demo_file/multispecific' ## or replace it with folder from your own google drive\n",
        "                           ## and remember to follow the dir structure in usage.md\n",
        "opt.video_path = './demo_file/multi_people_1080p.mp4' ## or replace it with video from your own google drive\n",
        "opt.output_path = './output/multi_test_multispecific.mp4'\n",
        "opt.temp_path = './tmp'\n",
        "opt.Arc_path = './arcface_model/arcface_checkpoint.tar'\n",
        "opt.name = 'people'\n",
        "opt.isTrain = False\n",
        "opt.use_mask = True  ## new feature up-to-date\n",
        "\n",
        "crop_size = opt.crop_size\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "f: /root/.local/share/jupyter/runtime/kernel-e4037db6-8f70-4d8f-a8f1-c81b6304785b.json\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/\n",
            "phase: test\n",
            "pic_a_path: G:/swap_data/ID/elon-musk-hero-image.jpeg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: False\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "UFt8zQrAMq9F",
        "outputId": "b0184b55-fc59-41b8-de28-51d3cf73ba32"
      },
      "source": [
        "pic_specific = opt.pic_specific_path\n",
        "crop_size = opt.crop_size\n",
        "multisepcific_dir = opt.multisepcific_dir\n",
        "\n",
        "torch.nn.Module.dump_patches = True\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "# The specific person to be swapped(source)\n",
        "source_specific_id_nonorm_list = []\n",
        "source_path = os.path.join(multisepcific_dir,'SRC_*')\n",
        "source_specific_images_path = sorted(glob.glob(source_path))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for source_specific_image_path in source_specific_images_path:\n",
        "        specific_person_whole = cv2.imread(source_specific_image_path)\n",
        "        specific_person_align_crop, _ = app.get(specific_person_whole,crop_size)\n",
        "        specific_person_align_crop_pil = Image.fromarray(cv2.cvtColor(specific_person_align_crop[0],cv2.COLOR_BGR2RGB))\n",
        "        specific_person = transformer_Arcface(specific_person_align_crop_pil)\n",
        "        specific_person = specific_person.view(-1, specific_person.shape[0], specific_person.shape[1], specific_person.shape    [2])\n",
        "        # convert numpy to tensor\n",
        "        specific_person = specific_person.cuda()\n",
        "        #create latent id\n",
        "        specific_person_downsample = F.interpolate(specific_person, size=(112,112))\n",
        "        specific_person_id_nonorm = model.netArc(specific_person_downsample)\n",
        "        source_specific_id_nonorm_list.append(specific_person_id_nonorm.clone())\n",
        "\n",
        "    # The person who provides id information (list)\n",
        "    target_id_norm_list = []\n",
        "    target_path = os.path.join(multisepcific_dir,'DST_*')\n",
        "    target_images_path = sorted(glob.glob(target_path))\n",
        "\n",
        "    for target_image_path in target_images_path:\n",
        "        img_a_whole = cv2.imread(target_image_path)\n",
        "        img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
        "        img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB))\n",
        "        img_a = transformer_Arcface(img_a_align_crop_pil)\n",
        "        img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
        "        # convert numpy to tensor\n",
        "        img_id = img_id.cuda()\n",
        "        #create latent id\n",
        "        img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
        "        latend_id = model.netArc(img_id_downsample)\n",
        "        latend_id = F.normalize(latend_id, p=2, dim=1)\n",
        "        target_id_norm_list.append(latend_id.clone())\n",
        "\n",
        "    assert len(target_id_norm_list) == len(source_specific_id_nonorm_list), \"The number of images in source and target  directory must be same !!!\"\n",
        "    video_swap(opt.video_path, target_id_norm_list,source_specific_id_nonorm_list, opt.id_thres, \\\n",
        "        model, app, opt.output_path,temp_results_dir=opt.temp_path,no_simswaplogo=opt.no_simswaplogo,use_mask=opt.use_mask)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained network G has fewer layers; The following are not initialized:\n",
            "['down0', 'first_layer', 'last_layer', 'up0']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-60c43277c405>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFace_detect_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'antelope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./insightface_func/models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx_id\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdet_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# The specific person to be swapped(source)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SimSwap/insightface_func/face_detect_crop_multi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, root)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'duplicated model task type, ignore:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaskname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m'detection'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty2GsyZZrI6"
      },
      "source": [],
      "execution_count": 15,
      "outputs": []
    }
  ]
}